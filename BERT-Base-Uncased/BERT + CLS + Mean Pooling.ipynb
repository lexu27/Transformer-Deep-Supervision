{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6QrLCOTjzzW"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install sentencepiece\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmus-ntxUXLM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4OW0qKyjzzY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import wandb\n",
    "import random, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "import re\n",
    "from torch.nn import Module\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import sys\n",
    "import gc\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYX_09FZjzzc"
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"seed\": [83, 55, 48],\n",
    "    \"model_name\": \"bert-base-uncased\",\n",
    "    \"max_length\": 512,\n",
    "    \"lr\": 2e-5, \n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 20,\n",
    "    \"dataset\": \"rte\",\n",
    "    \"type\": \"+ CLS + Mean Pooling\",\n",
    "\n",
    "    \"patience\": 6,\n",
    "\n",
    "    \"grad_accum\": 1,\n",
    "    \"pooler\": None,\n",
    "    \"dropout\": 0.1,\n",
    "    \"weight_decay\": 0.1,\n",
    "\n",
    "    \"layer_start\": 8,\n",
    "}\n",
    "CFG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLRAH4l_dpVE"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IW2NU8WKaprn"
   },
   "outputs": [],
   "source": [
    "data = load_dataset(\"glue\", CFG[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rk66iMNU9bLY"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxUD8XrX3SuY"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG[\"model_name\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESygDI-J96YR"
   },
   "outputs": [],
   "source": [
    "if CFG[\"dataset\"] == \"wnli\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence1\"], data[\"sentence2\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"sentence1\", \"idx\", \"sentence2\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"rte\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence1\"], data[\"sentence2\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"sentence1\", \"idx\", \"sentence2\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"mrpc\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence1\"], data[\"sentence2\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"sentence1\", \"idx\", \"sentence2\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"stsb\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence1\"], data[\"sentence2\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"sentence1\", \"idx\", \"sentence2\"], num_proc = 8)    \n",
    "elif CFG[\"dataset\"] == \"cola\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"idx\", \"sentence\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"sst2\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"idx\", \"sentence\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"qnli\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"question\"], data[\"sentence\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"idx\", \"question\", \"sentence\"], num_proc = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmUuQQt53MKE"
   },
   "outputs": [],
   "source": [
    "train = data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxS2Zq-j9Uw9"
   },
   "outputs": [],
   "source": [
    "val = data[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ylZ0EqF9dtG"
   },
   "outputs": [],
   "source": [
    "test = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUfekJjTAHlo"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLB37gJZCr3V"
   },
   "outputs": [],
   "source": [
    "train.with_format(\"torch\", device = device)\n",
    "val.with_format(\"torch\", device = device)\n",
    "test.with_format(\"torch\", device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-Fzlf-7jzzb"
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = \"[Your API Key]\"\n",
    "%env \"WANDB_API_KEY\" \"[Your API Key]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlrcXScDjzzb"
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VO2IGusFCwLX"
   },
   "outputs": [],
   "source": [
    "class WeightedLayerPooling(torch.nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ao6YGGsHZfn"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKcj-aeRXLdx"
   },
   "outputs": [],
   "source": [
    "class AccuracyTracker(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.num_correct = 0\n",
    "        self.total = 0\n",
    "        self.accuracy = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.num_correct += val\n",
    "        self.total += n\n",
    "        self.accuracy = self.num_correct / self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIj0e07d8crC"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config, vocab_length, data_loader_len):\n",
    "        super(Model, self).__init__()\n",
    "        self.config = config\n",
    "        self.vocab_length = vocab_length\n",
    "        self.base_model = AutoModel.from_pretrained(self.config['model_name'], output_hidden_states = True)  \n",
    "        self.base_model.resize_token_embeddings(vocab_length)\n",
    "\n",
    "        self.pooler = WeightedLayerPooling(self.base_model.config.num_hidden_layers, layer_start = self.config[\"layer_start\"])  \n",
    "        self._init_weights(self.pooler.layer_weights)\n",
    "\n",
    "        self.fc = nn.Linear(self.base_model.config.hidden_size, 1)\n",
    "\n",
    "        self._init_weights(self.fc)\n",
    "        self.data_loader_len = data_loader_len\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=CFG[\"dropout\"])\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        elif isinstance(module, nn.parameter.Parameter):\n",
    "            module.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n",
    "        else:\n",
    "            print(f\"Module of type {type(module)} cannot be initialized\")\n",
    "\n",
    "    def feature(self, inputs):\n",
    "\n",
    "        input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
    "    \n",
    "        x = self.base_model(input_ids = input_ids, attention_mask = attention_mask)[\"hidden_states\"]\n",
    "\n",
    "        x = torch.stack(x)\n",
    "        cls_embeddings = self.pooler(x)[:, 0]\n",
    "\n",
    "        return cls_embeddings\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        features = self.feature(inputs)\n",
    "\n",
    "        return self.fc(self.dropout(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPPDgVLsjzzd"
   },
   "source": [
    "# Packaging All The Above Functions into a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lREk9P6jzzg"
   },
   "outputs": [],
   "source": [
    "class DataModule():\n",
    "\n",
    "    def __init__(self, config, train, val, test, collate_fn):\n",
    "        self.config = config\n",
    "        self.train, self.val, self.test = train, val, test\n",
    "        self.collate_fn = collate_fn\n",
    "\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.train, batch_size=self.config[\"batch_size\"], shuffle = True, collate_fn = self.collate_fn, pin_memory=True, num_workers = 8)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.val, batch_size = self.config[\"batch_size\"], collate_fn = self.collate_fn, pin_memory=True, num_workers = 8)\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.test, batch_size = self.config[\"batch_size\"], collate_fn = self.collate_fn, pin_memory=True,  num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmHpjEfcwSC2"
   },
   "outputs": [],
   "source": [
    "def configure_optimizers(config, model):\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), weight_decay = config[\"weight_decay\"], lr=config[\"lr\"], correct_bias = True)\n",
    "\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = model.data_loader_len * config[\"epochs\"] // config[\"grad_accum\"] * 0.1, num_training_steps = model.data_loader_len * config[\"epochs\"] // config[\"grad_accum\"])    \n",
    "    \n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVPtW6szW6JV"
   },
   "outputs": [],
   "source": [
    "def train_fn(config, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    train_accuracy = AccuracyTracker()\n",
    "\n",
    "    pbar = tqdm(train_loader, desc = f\"Training Loop Epoch: {epoch}\", position=0, leave=True)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    latest_avg = None\n",
    "\n",
    "    latest_acc = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "\n",
    "        labels = batch.pop(\"labels\")\n",
    "\n",
    "        inputs = batch\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "\n",
    "        labels = labels.to(device).to(torch.float16)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            y_hat = model(inputs).reshape(-1)\n",
    "\n",
    "            train_loss = criterion(y_hat, labels)\n",
    "\n",
    "            scaled_loss = train_loss / config[\"grad_accum\"]\n",
    "        \n",
    "        losses.update(train_loss.item(), batch_size)\n",
    "\n",
    "\n",
    "        probs = torch.sigmoid(y_hat)\n",
    "\n",
    "        num_correct = torch.sum((probs > 0.5).to(int) == labels)\n",
    "        train_accuracy.update(num_correct, batch_size)\n",
    "        \n",
    "        scaler.scale(scaled_loss).backward()\n",
    "        \n",
    "\n",
    "        if ((batch_idx + 1) % config[\"grad_accum\"] == 0) or (batch_idx + 1 == model.data_loader_len):\n",
    "\n",
    "            scaler.unscale_(optimizer)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if not scheduler is None:\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "                for i, lr in enumerate(scheduler.get_last_lr()):\n",
    "                    wandb.log({f\"Layer {i} Learning Rate\": lr})\n",
    "\n",
    "            latest_avg = f\"{losses.avg:.4f}\"\n",
    "\n",
    "            latest_acc = f\"{train_accuracy.accuracy:.4f}\"\n",
    "\n",
    "        text = f\"Epoch: {epoch} | Training_accuracy: {latest_acc} | Training Loss_avg: {latest_avg} | Training Loss_step: {losses.val:.4f} | Learning Rate: {scheduler.get_last_lr()[0]:.4f}\" if not scheduler is None else f\"Epoch: {epoch} | Training Loss_avg: {latest_avg} | Training Loss_step: {losses.val:.4f}\"\n",
    "\n",
    "        pbar.set_postfix_str(text)\n",
    "\n",
    "        pbar.refresh()\n",
    "\n",
    "        wandb.log({f\"Training Loss_step\": losses.val})\n",
    "\n",
    "        wandb.log({f\"Training Accuracy Step\": train_accuracy.accuracy})\n",
    "\n",
    "    wandb.log({f\"Training Loss Epoch\": losses.avg})\n",
    "    wandb.log({f\"Training Accuracy Epoch\": train_accuracy.accuracy})\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJhNb7m7XEBn"
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    accuracy = AccuracyTracker()\n",
    "\n",
    "    pbar = tqdm(valid_loader, desc = f\"Validation Loop Epoch: {epoch}\", position=0, leave=True)\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        \n",
    "        labels = batch.pop(\"labels\")\n",
    "\n",
    "        inputs = batch\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "\n",
    "        labels = labels.to(device).to(torch.float16)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        model = model.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs).reshape(-1)\n",
    "\n",
    "        val_loss = criterion(preds, labels).item()\n",
    "\n",
    "        losses.update(val_loss, batch_size)\n",
    "        \n",
    "        probs = torch.sigmoid(preds)\n",
    "\n",
    "        num_correct = torch.sum((probs > 0.5).to(int) == labels)\n",
    "        accuracy.update(num_correct, batch_size)\n",
    "\n",
    "        pbar.set_postfix_str(f\"Epoch: {epoch} | Validation Loss_avg: {losses.avg:.4f} | Validation_accuracy_step: {accuracy.accuracy}\")\n",
    "\n",
    "    wandb.log({f\"Validation Loss Epoch\": losses.avg})\n",
    "    wandb.log({f\"Validation Accuracy Epoch\": accuracy.accuracy})\n",
    "\n",
    "    return losses.avg, accuracy.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfC3gU9jxwA9"
   },
   "outputs": [],
   "source": [
    "def test_fn(test_loader, model, criterion, device, checkpoint):\n",
    "    with torch.no_grad():\n",
    "        losses = AverageMeter()\n",
    "        accuracy = AccuracyTracker()\n",
    "\n",
    "        saved = torch.load(checkpoint)\n",
    "        model.load_state_dict(saved[\"model_state_dict\"])\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = torch.tensor([0]).to(device).to(torch.float16)\n",
    "\n",
    "        pbar = tqdm(test_loader, desc = f\"Getting Test Predictions\", position=0, leave=True)\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            labels = batch.pop(\"labels\")\n",
    "\n",
    "            inputs = batch\n",
    "\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device)\n",
    "\n",
    "            labels = labels.to(device).to(torch.float16)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            model = model.to(device)\n",
    "            \n",
    "            y_hat = model(inputs)\n",
    "\n",
    "            val_loss = criterion(y_hat.flatten(), labels)\n",
    "\n",
    "            probs = torch.sigmoid(y_hat)\n",
    "\n",
    "            num_correct = torch.sum((probs.flatten() > 0.5).to(int) == labels)\n",
    "\n",
    "            losses.update(val_loss, batch_size)\n",
    "\n",
    "            accuracy.update(num_correct, batch_size)\n",
    "\n",
    "        wandb.log({f\"Validation Accuracy\": accuracy.accuracy})\n",
    "\n",
    "        print(f\"Validation Accuracy: {accuracy.accuracy}\")\n",
    "\n",
    "        return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dqlGGJdqUS0"
   },
   "outputs": [],
   "source": [
    "class ModelTracker():\n",
    "    def __init__(self, patience, base_path, model, path, optimizer, scheduler, mode = \"maximize\", metric_name = \"accuracy\"):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.missed = 0\n",
    "        self.path = path\n",
    "        self.model = model\n",
    "        self.base_path = base_path\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric = float(\"-inf\") if self.mode == \"maximize\" else float(\"inf\")\n",
    "        self.metric_name = metric_name\n",
    "\n",
    "    def update(self, value, epoch):\n",
    "        if self.mode == \"maximize\":\n",
    "            if value > self.metric:\n",
    "                print(f\"Validation {self.metric_name} rose from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n",
    "                self.metric = value\n",
    "                \n",
    "                torch.save({\n",
    "                    \"epoch\": epoch, \n",
    "                    \"model_state_dict\": self.model.state_dict(), \n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"accuracy\": self.metric,\n",
    "                    \"scheduler\": self.scheduler.state_dict()\n",
    "                }, f\"{self.base_path}/{self.path}\")\n",
    "\n",
    "                print(f\"Saved to model to {self.base_path}/{self.path}!\")\n",
    "\n",
    "                self.missed = 0\n",
    "\n",
    "            else:\n",
    "                print(f\"Validation {self.metric_name} fell from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n",
    "                print(f\"Model did not improve on epoch {epoch}\")\n",
    "                self.missed += 1\n",
    "        else:\n",
    "            if value < self.metric:\n",
    "                print(f\"Validation {self.metric_name} fell from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n",
    "                self.metric = value\n",
    "                \n",
    "                torch.save({\n",
    "                    \"epoch\": epoch, \n",
    "                    \"model_state_dict\": self.model.state_dict(), \n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"loss\": self.metric,\n",
    "                    \"scheduler\": self.scheduler.state_dict()\n",
    "                }, f\"{self.base_path}/{self.path}\")\n",
    "\n",
    "                self.missed = 0\n",
    "\n",
    "                print(f\"Saved to model to {self.base_path}/{self.path}!\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Validation {self.metric_name} rose from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n",
    "                print(f\"Model did not improve on epoch {epoch}\")\n",
    "                self.missed += 1\n",
    "\n",
    "    def get_full_path(self):\n",
    "        return f\"{self.base_path}/{self.path}\"\n",
    "        \n",
    "    def check_improvement(self):\n",
    "        return (self.missed < self.patience if self.mode == \"maximize\" else self.missed > self.patience) and (self.missed < self.patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruzVJ42ujzzj"
   },
   "outputs": [],
   "source": [
    "def train_loop(train, val, test, data_collator, config, device, weights=None, base_path = \"./\"):\n",
    "    for seed in config[\"seed\"]:\n",
    "        seed_everything(seed)\n",
    "\n",
    "        wandb.init(project=\"{Your Project}\", entity = \"{Your Username}\", group = config[\"dataset\"], config = config, job_type = f\"{config['model_name']} {config['type']}\", save_code = True, reinit = True, name = f\"Seed {seed}\")\n",
    "\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        validation_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        dataset = DataModule(config, train, val, test, data_collator)\n",
    "\n",
    "        train_loader = dataset.train_dataloader()\n",
    "\n",
    "        val_loader = dataset.val_dataloader()\n",
    "\n",
    "        model = Model(config, len(config[\"tokenizer\"]), len(train_loader))\n",
    "\n",
    "        model = model.to(device)\n",
    "\n",
    "\n",
    "        optimizer, scheduler = configure_optimizers(config, model)\n",
    "\n",
    "        tracker = ModelTracker(config[\"patience\"], base_path, model, f\"seed-{seed}.pt\", optimizer, scheduler)\n",
    "\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "\n",
    "            train_loss = train_fn(config, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "            val_loss, val_accuracy = valid_fn(val_loader, model, validation_criterion, device, epoch)\n",
    "\n",
    "            tracker.update(val_accuracy, epoch)\n",
    "\n",
    "            if not tracker.check_improvement():\n",
    "                print(f\"Stopping the model at epoch {epoch} since the model did not improve!\")\n",
    "                break\n",
    "\n",
    "\n",
    "        checkpoint = tracker.get_full_path()\n",
    "\n",
    "        wandb.save(checkpoint)\n",
    "\n",
    "        test_fn(val_loader, model, validation_criterion, device, checkpoint)\n",
    "\n",
    "        del dataset, model\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGhABbNI2Yz_"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9jBz0mZUXLZ"
   },
   "outputs": [],
   "source": [
    "train_loop(train, val, test, data_collator, CFG, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
