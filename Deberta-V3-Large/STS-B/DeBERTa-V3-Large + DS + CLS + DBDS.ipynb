{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6QrLCOTjzzW"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install sentencepiece\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmus-ntxUXLM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4OW0qKyjzzY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import glob\n",
    "import os\n",
    "import wandb\n",
    "import random, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "import re\n",
    "from torch.nn import Module\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import sys\n",
    "import gc\n",
    "from transformers import DataCollatorWithPadding\n",
    "from scipy.stats.mstats import pearsonr\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYX_09FZjzzc"
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"seed\": [83, 55, 48],\n",
    "    \"model_name\": \"microsoft/deberta-v3-large\",\n",
    "    \"max_length\": 512,\n",
    "    \"lr\": 2e-5, \n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 20,\n",
    "    \"num_warmup_steps\": 100,\n",
    "    \"dataset\": \"stsb\",\n",
    "    \"type\": \"+ DS + CLS + AAM\",\n",
    "\n",
    "    \"patience\": 6,\n",
    "\n",
    "    \"grad_accum\": 4,\n",
    "    \"pooler\": \"deep\",\n",
    "    \"dropout\": 0.1,\n",
    "    \"weight_decay\": 0.1,\n",
    "\n",
    "    \"layer_start\": 20,\n",
    "    \"aux_weight\": 0.5,\n",
    "}\n",
    "CFG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLRAH4l_dpVE"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IW2NU8WKaprn"
   },
   "outputs": [],
   "source": [
    "data = load_dataset(\"glue\", CFG[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rk66iMNU9bLY"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxUD8XrX3SuY"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG[\"model_name\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESygDI-J96YR"
   },
   "outputs": [],
   "source": [
    "if CFG[\"dataset\"] == \"wnli\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence1\"], data[\"sentence2\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"sentence1\", \"idx\", \"sentence2\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"rte\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence1\"], data[\"sentence2\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"sentence1\", \"idx\", \"sentence2\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"mrpc\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence1\"], data[\"sentence2\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"sentence1\", \"idx\", \"sentence2\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"stsb\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence1\"], data[\"sentence2\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"sentence1\", \"idx\", \"sentence2\"], num_proc = 8)    \n",
    "elif CFG[\"dataset\"] == \"cola\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"idx\", \"sentence\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"sst2\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"sentence\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"idx\", \"sentence\"], num_proc = 8)\n",
    "elif CFG[\"dataset\"] == \"qnli\":\n",
    "    data = data.map(lambda data: tokenizer(data[\"question\"], data[\"sentence\"], padding=True, max_length = CFG[\"max_length\"], truncation = True, return_token_type_ids = False), batched = True, remove_columns = [\"idx\", \"question\", \"sentence\"], num_proc = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmUuQQt53MKE"
   },
   "outputs": [],
   "source": [
    "train = data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxS2Zq-j9Uw9"
   },
   "outputs": [],
   "source": [
    "val = data[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ylZ0EqF9dtG"
   },
   "outputs": [],
   "source": [
    "test = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUfekJjTAHlo"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLB37gJZCr3V"
   },
   "outputs": [],
   "source": [
    "train.with_format(\"torch\", device = device)\n",
    "val.with_format(\"torch\", device = device)\n",
    "test.with_format(\"torch\", device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-Fzlf-7jzzb"
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = \"[Your API Key]\"\n",
    "%env \"WANDB_API_KEY\" \"[Your API Key]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlrcXScDjzzb"
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ao6YGGsHZfn"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKcj-aeRXLdx"
   },
   "outputs": [],
   "source": [
    "class PearsonTracker(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.pearson = 0\n",
    "\n",
    "    def update(self, x, y):\n",
    "        self.x.extend(x.detach().cpu().numpy())\n",
    "        self.y.extend(y.detach().cpu().numpy())\n",
    "        self.pearson = pearsonr(self.x, self.y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIj0e07d8crC"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config, vocab_length, data_loader_len):\n",
    "        super(Model, self).__init__()\n",
    "        self.config = config\n",
    "        self.vocab_length = vocab_length\n",
    "        self.base_model = AutoModel.from_pretrained(self.config[\"model_name\"], output_hidden_states = True)  \n",
    "        self.base_model.resize_token_embeddings(vocab_length)\n",
    "        self.base_model = self.base_model\n",
    "\n",
    "        self.fc = nn.Linear(self.base_model.config.hidden_size, 1)\n",
    "        self.span = self.base_model.config.num_hidden_layers - self.config[\"layer_start\"] + 1\n",
    "\n",
    "        self.fcs = []\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=CFG[\"dropout\"])\n",
    "\n",
    "        if self.config[\"pooler\"] == \"deep\":\n",
    "            for _ in range(self.span):\n",
    "                layer = nn.Linear(self.base_model.config.hidden_size, 1)\n",
    "                self._init_weights(layer)\n",
    "                self.fcs.append(layer)\n",
    "\n",
    "        self._init_weights(self.fc)\n",
    "        self.data_loader_len = data_loader_len\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        elif isinstance(module, nn.parameter.Parameter):\n",
    "            module.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n",
    "        else:\n",
    "            print(f\"Module of type {type(module)} cannot be initialized\")\n",
    "\n",
    "    def feature(self, inputs):\n",
    "\n",
    "        if self.config[\"pooler\"] == \"deep\":\n",
    "            input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
    "        \n",
    "            x = self.base_model(input_ids = input_ids, attention_mask = attention_mask)[\"hidden_states\"]\n",
    "\n",
    "            x = torch.stack(x)\n",
    "\n",
    "            return x[self.config[\"layer_start\"]:, :, :, :]\n",
    "            \n",
    "        else:\n",
    "            input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
    "        \n",
    "            x = self.base_model(input_ids = input_ids, attention_mask = attention_mask)[\"last_hidden_state\"]\n",
    "\n",
    "            return inputs[:, 0, :]\n",
    "\n",
    "            \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        features = self.feature(inputs)\n",
    "\n",
    "        if self.config[\"pooler\"] == \"deep\":\n",
    "\n",
    "            outputs = []\n",
    "\n",
    "            layers = []\n",
    "\n",
    "            for layer_num, layer in enumerate(features):\n",
    "                \n",
    "                layers.append(self.dropout(layer[:, 0, :]))\n",
    "                \n",
    "                outputs.append(self.fcs[layer_num](layers[-1]))\n",
    "\n",
    "            outputs = torch.stack(outputs)\n",
    "\n",
    "            layers = torch.stack(layers)\n",
    "\n",
    "            final_cls = torch.max(layers, dim = 0)[0]\n",
    "\n",
    "            pred = self.fc(final_cls)\n",
    "            \n",
    "            return outputs, pred\n",
    "\n",
    "        return self.fc(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPPDgVLsjzzd"
   },
   "source": [
    "# Packaging All The Above Functions into a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lREk9P6jzzg"
   },
   "outputs": [],
   "source": [
    "class DataModule():\n",
    "\n",
    "    def __init__(self, config, train, val, test, collate_fn):\n",
    "        self.config = config\n",
    "        self.train, self.val, self.test = train, val, test\n",
    "        self.collate_fn = collate_fn\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.train, batch_size=self.config[\"batch_size\"], shuffle = True, collate_fn = self.collate_fn, pin_memory=True, num_workers = 8)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.val, batch_size = self.config[\"batch_size\"], collate_fn = self.collate_fn, pin_memory=True, num_workers = 8)\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.test, batch_size = self.config[\"batch_size\"], collate_fn = self.collate_fn, pin_memory=True,  num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmHpjEfcwSC2"
   },
   "outputs": [],
   "source": [
    "def configure_optimizers(config, model):\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), weight_decay = config[\"weight_decay\"], lr=config[\"lr\"], correct_bias = True)\n",
    "\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = config[\"num_warmup_steps\"], num_training_steps = model.data_loader_len * config[\"epochs\"] // config[\"grad_accum\"])    \n",
    "    \n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVPtW6szW6JV"
   },
   "outputs": [],
   "source": [
    "def train_fn(config, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "\n",
    "    losses = [AverageMeter() for i in range(model.span + 1)]\n",
    "    overall_loss = AverageMeter()\n",
    "    train_corr = PearsonTracker()\n",
    "\n",
    "    pbar = tqdm(train_loader, desc = f\"Training Loop Epoch: {epoch}\", position=0, leave=True)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    latest_avg = None\n",
    "\n",
    "    latest_corr = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "\n",
    "        labels = batch.pop(\"labels\")\n",
    "\n",
    "        inputs = batch\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "\n",
    "        labels = labels.to(device).to(torch.float16)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs, y_hat = model(inputs)\n",
    "\n",
    "            train_loss = criterion(y_hat.flatten(), labels)\n",
    "\n",
    "            losses[-1].update(train_loss, batch_size)\n",
    "\n",
    "            for idx in range(len(outputs) - 1, -1, -1):\n",
    "                aux_loss = config[\"aux_weight\"] * criterion(outputs[idx].flatten(), labels)\n",
    "            \n",
    "                losses[(idx)].update(aux_loss, batch_size)\n",
    "            \n",
    "                train_loss += aux_loss\n",
    "\n",
    "            overall_loss.update(train_loss, batch_size)\n",
    "\n",
    "            scaled_loss = train_loss / config[\"grad_accum\"]\n",
    "        \n",
    "\n",
    "        train_corr.update(y_hat, labels)\n",
    "        \n",
    "        scaler.scale(scaled_loss).backward()\n",
    "        \n",
    "\n",
    "        if ((batch_idx + 1) % config[\"grad_accum\"] == 0) or (batch_idx + 1 == model.data_loader_len):\n",
    "\n",
    "            scaler.unscale_(optimizer)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if not scheduler is None:\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "\n",
    "            latest_avg = f\"{overall_loss.avg:.4f}\"\n",
    "\n",
    "            latest_corr = f\"{train_corr.pearson:.4f}\"\n",
    "\n",
    "\n",
    "        text = f\"Epoch: {epoch} | Training_pearson: {latest_corr} | Training Loss_avg: {latest_avg} | Training Loss_step: {overall_loss.val:.4f} | Learning Rate: {scheduler.get_last_lr()[0]:.4f}\" if not scheduler is None else f\"Epoch: {epoch} | Training Loss_avg: {latest_avg} | Training Loss_step: {overall_loss.val:.4f}\"\n",
    "\n",
    "        pbar.set_postfix_str(text)\n",
    "\n",
    "        pbar.refresh()\n",
    "\n",
    "        \n",
    "        for idx, loss in enumerate(losses):\n",
    "            if idx < len(losses) - 1:\n",
    "                wandb.log({f\"Training Loss Step Layer {idx + config['layer_start']}\": loss.val})\n",
    "                continue\n",
    "            wandb.log({f\"Training Loss Step Output Layer\": loss.val})\n",
    "\n",
    "        wandb.log({f\"Training Pearson Step\": train_corr.pearson})\n",
    "\n",
    "    wandb.log({f\"Training Pearson Epoch\": train_corr.pearson})\n",
    "\n",
    "    wandb.log({f\"Overall Training Loss Epoch\": overall_loss.avg})\n",
    "\n",
    "    return overall_loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJhNb7m7XEBn"
   },
   "outputs": [],
   "source": [
    "def valid_fn(config, valid_loader, model, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = [AverageMeter() for i in range(model.span + 1)]\n",
    "    overall_loss = AverageMeter()\n",
    "    corr = PearsonTracker()\n",
    "\n",
    "    pbar = tqdm(valid_loader, desc = f\"Validation Loop Epoch: {epoch}\", position=0, leave=True)\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        \n",
    "        labels = batch.pop(\"labels\")\n",
    "\n",
    "        inputs = batch\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "\n",
    "        labels = labels.to(device).to(torch.float16)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        model = model.to(device)\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs, y_hat = model(inputs)\n",
    "\n",
    "            val_loss = criterion(y_hat.flatten(), labels)\n",
    "\n",
    "            losses[-1].update(val_loss, batch_size)\n",
    "\n",
    "            for idx in range(len(outputs) - 1, -1, -1):\n",
    "                aux_loss = config[\"aux_weight\"] * criterion(outputs[idx].flatten(), labels)\n",
    "                losses[idx].update(aux_loss, batch_size)\n",
    "                val_loss += aux_loss\n",
    "\n",
    "        overall_loss.update(val_loss.item(), batch_size)\n",
    "\n",
    "        corr.update(y_hat, labels)\n",
    "\n",
    "        pbar.set_postfix_str(f\"Epoch: {epoch} | Validation Loss_avg: {overall_loss.avg:.4f} | Validation_pearson_step: {corr.pearson}\")\n",
    "    \n",
    "    for idx, loss in enumerate(losses):\n",
    "        if idx < len(losses) - 1:\n",
    "            wandb.log({f\"Validation Loss Epoch Layer {idx + config['layer_start']}\": loss.avg})\n",
    "            continue\n",
    "        wandb.log({f\"Validation Loss Epoch Output Layer\": loss.avg})\n",
    "\n",
    "    wandb.log({\"Overall Validation Loss Epoch\": overall_loss.avg})\n",
    "\n",
    "    wandb.log({f\"Validation Pearson Epoch\": corr.pearson})\n",
    "\n",
    "    return overall_loss.avg, corr.pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfC3gU9jxwA9"
   },
   "outputs": [],
   "source": [
    "def test_fn(config, test_loader, model, criterion, device, checkpoint):\n",
    "    with torch.no_grad():\n",
    "        losses = AverageMeter()\n",
    "        corr = PearsonTracker()\n",
    "\n",
    "        saved = torch.load(checkpoint)\n",
    "        model.load_state_dict(saved[\"model_state_dict\"])\n",
    "        model.eval()\n",
    "\n",
    "        pbar = tqdm(test_loader, desc = f\"Getting Test Predictions\", position=0, leave=True)\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            labels = batch.pop(\"labels\")\n",
    "\n",
    "            inputs = batch\n",
    "\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device)\n",
    "\n",
    "            labels = labels.to(device).to(torch.float16)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            model = model.to(device)\n",
    "            \n",
    "            outputs, y_hat = model(inputs)\n",
    "\n",
    "            val_loss = criterion(y_hat.flatten(), labels)\n",
    "\n",
    "            for idx, output in enumerate(outputs[:-1]):\n",
    "                val_loss += config[\"aux_weight\"] + criterion(output.flatten(), labels)\n",
    "\n",
    "            losses.update(val_loss, batch_size)\n",
    "\n",
    "            corr.update(y_hat, labels)\n",
    "\n",
    "        wandb.log({f\"Validation Pearson\": corr.pearson})\n",
    "\n",
    "        print(f\"Validation Pearson: {corr.pearson}\")\n",
    "\n",
    "        return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dqlGGJdqUS0"
   },
   "outputs": [],
   "source": [
    "class ModelTracker():\n",
    "    def __init__(self, patience, base_path, model, path, optimizer, scheduler, mode = \"maximize\", metric_name = \"accuracy\"):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.missed = 0\n",
    "        self.path = path\n",
    "        self.model = model\n",
    "        self.base_path = base_path\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric = float(\"-inf\") if self.mode == \"maximize\" else float(\"inf\")\n",
    "        self.metric_name = metric_name\n",
    "\n",
    "    def update(self, value, epoch):\n",
    "        if self.mode == \"maximize\":\n",
    "            if value > self.metric:\n",
    "                print(f\"Validation {self.metric_name} rose from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n",
    "                self.metric = value\n",
    "                \n",
    "                torch.save({\n",
    "                    \"epoch\": epoch, \n",
    "                    \"model_state_dict\": self.model.state_dict(), \n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"accuracy\": self.metric,\n",
    "                    \"scheduler\": self.scheduler.state_dict()\n",
    "                }, f\"{self.base_path}/{self.path}\")\n",
    "\n",
    "                print(f\"Saved to model to {self.base_path}/{self.path}!\")\n",
    "\n",
    "                self.missed = 0\n",
    "\n",
    "            else:\n",
    "                print(f\"Validation {self.metric_name} fell from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n",
    "                print(f\"Model did not improve on epoch {epoch}\")\n",
    "                self.missed += 1\n",
    "        else:\n",
    "            if value < self.metric:\n",
    "                print(f\"Validation {self.metric_name} fell from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n",
    "                self.metric = value\n",
    "                \n",
    "                torch.save({\n",
    "                    \"epoch\": epoch, \n",
    "                    \"model_state_dict\": self.model.state_dict(), \n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"loss\": self.metric,\n",
    "                    \"scheduler\": self.scheduler.state_dict()\n",
    "                }, f\"{self.base_path}/{self.path}\")\n",
    "\n",
    "                self.missed = 0\n",
    "\n",
    "                print(f\"Saved to model to {self.base_path}/{self.path}!\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Validation {self.metric_name} rose from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n",
    "                print(f\"Model did not improve on epoch {epoch}\")\n",
    "                self.missed += 1\n",
    "\n",
    "    def get_full_path(self):\n",
    "        return f\"{self.base_path}/{self.path}\"\n",
    "        \n",
    "    def check_improvement(self):\n",
    "        return (self.missed < self.patience if self.mode == \"maximize\" else self.missed > self.patience) and (self.missed < self.patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruzVJ42ujzzj"
   },
   "outputs": [],
   "source": [
    "def train_loop(train, val, test, data_collator, config, device, weights=None, base_path = \"./\"):\n",
    "    for seed in config[\"seed\"]:\n",
    "        seed_everything(seed)\n",
    "\n",
    "        wandb.init(project=\"{Your Project}\", entity = \"{Your Username}\", group = config[\"dataset\"], config = config, job_type = f\"{config['model_name']} {config['type']}\", save_code = True, reinit = True, name = f\"Seed {seed}\")\n",
    "\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        validation_criterion = torch.nn.MSELoss()\n",
    "\n",
    "        dataset = DataModule(config, train, val, test, data_collator)\n",
    "\n",
    "        train_loader = dataset.train_dataloader()\n",
    "\n",
    "        val_loader = dataset.val_dataloader()\n",
    "\n",
    "        model = Model(config, len(config[\"tokenizer\"]), len(train_loader))\n",
    "        \n",
    "        model = model.to(device)\n",
    "\n",
    "        for i, fc in enumerate(model.fcs):\n",
    "            model.fcs[i] = fc.to(device)\n",
    "\n",
    "        optimizer, scheduler = configure_optimizers(config, model)\n",
    "\n",
    "        tracker = ModelTracker(config[\"patience\"], base_path, model, f\"seed-{seed}.pt\", optimizer, scheduler, metric_name = \"Pearson Correlation\")\n",
    "\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "\n",
    "            train_loss = train_fn(config, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "            val_loss, val_accuracy = valid_fn(config, val_loader, model, validation_criterion, device, epoch)\n",
    "\n",
    "            tracker.update(val_accuracy, epoch)\n",
    "\n",
    "            if not tracker.check_improvement():\n",
    "                print(f\"Stopping the model at epoch {epoch} since the model did not improve!\")\n",
    "                break\n",
    "\n",
    "\n",
    "        checkpoint = tracker.get_full_path()\n",
    "\n",
    "        wandb.save(checkpoint)\n",
    "\n",
    "        test_fn(config, val_loader, model, validation_criterion, device, checkpoint)\n",
    "\n",
    "        del dataset, model\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGhABbNI2Yz_"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXBTlcHPkUGD"
   },
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9jBz0mZUXLZ"
   },
   "outputs": [],
   "source": [
    "train_loop(train, val, test, data_collator, CFG, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRuuJZIAYz5U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrfPAilwoOH5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcQCJvBgDGMb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "548_d2-Xyd_-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
